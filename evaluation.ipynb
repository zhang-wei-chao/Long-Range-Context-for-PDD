{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc99240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"hf_models/pythia-4.9B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10712cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep(x, score):\n",
    "    fpr, tpr, _ = roc_curve(x, -score)\n",
    "    acc = np.max(1-(fpr+(1-tpr))/2)\n",
    "    return fpr, tpr, auc(fpr, tpr), acc\n",
    "\n",
    "\n",
    "def evaluate(es, fpr_threshold=0.05):\n",
    "    answers = []\n",
    "    metric2predictions = defaultdict(list)\n",
    "    for e in es:\n",
    "        answers.append(e[\"label\"])\n",
    "        for metric in e[\"pred\"].keys():\n",
    "            metric2predictions[metric].append(e[\"pred\"][metric])\n",
    "\n",
    "    for metric, predictions in metric2predictions.items():\n",
    "        fpr, tpr,  auc, acc = sweep(np.array(answers, dtype=bool), np.array(predictions))\n",
    "        low = tpr[np.where(fpr < fpr_threshold)[0][-1]]\n",
    "        print(\"Attack %s AUC %.4f, Accuracy %.4f, TPR@5FPR of %.4f\\n\" %(metric, auc, acc, low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d4392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"output/13_0.8\"\n",
    "data_file = \"pythia-6-9B\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb4db1",
   "metadata": {},
   "source": [
    "## original prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47f3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_dir, f\"{data_file}.pkl\")\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b78f644",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10404, 187, 187, 1145, 10404, 13, 3690, 15, 310, 247, 4156, 1345, 2567, 1754, 275, 2615, 790, 6121, 13, 11637, 15, 733, 24357, 285, 10169, 10796, 73, 656, 982, 11369, 9864, 3694, 323, 1885, 2216, 13, 5175, 285, 4254, 15, 743, 10404, 369, 11420, 275, 10333, 407, 2516, 4235, 29963, 15, 4235, 29963, 4211, 521, 1600, 275, 253, 2567, 281, 18875, 5347, 1346, 275, 9725, 15, 743, 10404, 2427, 1345, 327, 13170, 4877, 50, 275, 8441, 15, 496, 253, 5307, 84, 13, 743, 10404, 1160, 7418, 45587, 273, 643, 11369, 2216, 4413, 13, 28635, 3081, 4302, 323, 6514, 8062, 13, 23598, 2216, 13, 285, 643, 12057, 1783, 15, 743, 10404, 3395, 247, 4445, 273, 253, 13170, 4877, 50, 14, 2313, 3605, 327, 4565, 3495, 13, 6247, 15, 187, 187, 9873, 1831, 366, 2892, 187, 187, 3980, 304, 968, 187, 510, 2934, 323, 743, 10404, 369, 806, 20913, 407, 2516, 4235, 29963, 1223, 2444, 387, 253, 4255, 272, 5967, 22042, 34322, 18196, 275, 253, 11994, 84, 15, 2058, 253, 673, 13, 19414, 2684, 6486, 3284, 1783, 313, 12297, 34, 10, 407, 1133, 15, 4255, 272, 5967, 10945, 4235, 29963, 434, 2934, 281, 3772, 366, 20015, 34, 407, 6684, 2087, 4096, 11369, 3694, 13, 594, 4235, 29963, 1669, 253, 2567, 275, 16648, 281, 1287, 253, 3694, 327, 521, 1211, 15, 754, 11420, 743, 10404, 762, 253, 1416, 4235, 29963, 10330, 13869, 3690, 15, 313, 52, 1719, 42, 10, 253, 1735, 807, 13, 2444, 562, 273, 521, 6389, 5967, 275, 22119, 15, 187, 187, 12455, 29963, 3715, 253, 3302, 743, 10404, 3694, 327, 18750, 14, 35817, 285, 908, 247, 2022, 6301, 4382, 326, 369, 33437, 407, 253, 4964, 15, 4255, 272, 5967, 14565, 4235, 29963, 347, 247, 24773, 13, 762, 253, 1617, 326]\n",
      "290 tensor([1.4213e-05, 1.1073e-02, 5.1061e-01, 3.3153e-02, 9.4302e-01, 8.7808e-02,\n",
      "        2.8431e-01, 7.1386e-01, 5.0370e-01, 7.4698e-01, 1.9370e-01, 5.1044e-05,\n",
      "        7.9846e-01, 7.3271e-02, 9.7876e-01, 2.6843e-01, 9.7739e-01, 9.9957e-01,\n",
      "        9.8634e-01, 9.3982e-01, 2.6656e-01, 2.2907e-01, 2.0154e-01, 3.7745e-01,\n",
      "        1.8199e-01, 2.8951e-03, 8.4314e-01, 8.4309e-01, 9.7968e-01, 1.1235e-02,\n",
      "        4.6223e-01, 8.7703e-01, 1.6516e-01, 2.4775e-02, 4.3545e-01, 6.2973e-01,\n",
      "        3.6617e-02, 2.6451e-01, 5.7144e-04, 5.0732e-01, 1.8767e-01, 9.9803e-01,\n",
      "        5.9446e-02, 6.7161e-01, 8.2223e-01, 2.0788e-03, 5.1353e-01, 3.4804e-02,\n",
      "        1.8691e-03, 2.2348e-01, 1.4381e-01, 1.9064e-02, 9.9536e-01, 4.7315e-02,\n",
      "        2.3199e-01, 1.5503e-01, 8.1753e-01, 5.9704e-01, 9.4727e-01, 4.8002e-01,\n",
      "        6.2072e-03, 6.9075e-01, 2.8878e-01, 6.2479e-01, 3.5490e-02, 5.9670e-01,\n",
      "        6.7039e-02, 9.9802e-01, 1.3251e-02, 9.8734e-01, 3.3132e-01, 1.2684e-01,\n",
      "        9.9974e-01, 9.9994e-01, 6.8239e-01, 7.5256e-02, 5.2658e-01, 1.1549e-01,\n",
      "        2.0526e-02, 3.7214e-02, 9.4882e-01, 7.7383e-01, 5.5468e-01, 9.9949e-01,\n",
      "        1.3186e-02, 1.1039e-02, 8.7741e-01, 1.1138e-01, 2.3758e-01, 2.5979e-01,\n",
      "        2.8326e-03, 1.0188e-01, 3.0035e-01, 2.0831e-03, 1.9322e-03, 3.0446e-02,\n",
      "        4.8101e-02, 5.9191e-03, 3.9703e-01, 5.1809e-01, 6.8094e-03, 5.8170e-02,\n",
      "        7.3134e-01, 3.2642e-01, 2.9154e-02, 7.0764e-03, 2.3169e-03, 3.9047e-01,\n",
      "        9.2812e-02, 9.9909e-01, 1.6550e-02, 5.3477e-01, 7.9936e-03, 9.5404e-01,\n",
      "        5.0029e-01, 6.3093e-02, 9.9954e-01, 9.9986e-01, 5.0397e-01, 9.6082e-01,\n",
      "        3.8241e-01, 1.2836e-01, 1.1378e-01, 1.8514e-02, 9.9699e-01, 4.1526e-03,\n",
      "        8.2393e-01, 7.6889e-01, 9.9308e-01, 1.1039e-02, 9.9538e-01, 9.8162e-01,\n",
      "        3.7993e-01, 8.2675e-01, 6.3291e-01, 3.8394e-02, 9.9787e-01, 9.9908e-01,\n",
      "        4.1809e-01, 9.9785e-02, 1.4686e-02, 6.6456e-01, 4.0193e-01, 9.9860e-01,\n",
      "        3.6050e-01, 6.5481e-02, 4.5386e-01, 3.6718e-01, 7.8741e-01, 9.3407e-01,\n",
      "        9.9630e-01, 9.6940e-02, 2.3142e-01, 3.7544e-01, 2.1510e-01, 8.1989e-03,\n",
      "        9.8750e-01, 9.9927e-01, 2.9125e-05, 3.9295e-01, 4.5891e-01, 5.6433e-01,\n",
      "        4.9504e-02, 2.2843e-01, 9.9866e-01, 8.4692e-01, 3.4327e-02, 5.3173e-01,\n",
      "        9.1366e-01, 8.8092e-01, 2.2679e-02, 1.4100e-03, 1.6849e-03, 8.7196e-01,\n",
      "        7.0845e-01, 2.5128e-01, 9.2148e-01, 9.9936e-01, 9.0767e-01, 5.8430e-02,\n",
      "        6.3013e-01, 2.7196e-01, 2.1464e-03, 9.9923e-01, 9.9925e-01, 1.4931e-04,\n",
      "        5.0313e-01, 9.9866e-01, 9.0601e-01, 2.7401e-01, 8.6942e-02, 3.1386e-01,\n",
      "        9.9943e-01, 4.1951e-01, 9.9358e-01, 2.1342e-02, 1.0539e-01, 2.8857e-04,\n",
      "        3.7476e-01, 2.0778e-03, 2.2070e-01, 1.5133e-01, 3.4472e-02, 7.8259e-01,\n",
      "        9.9975e-01, 3.5037e-01, 2.9169e-01, 9.1107e-01, 1.0064e-01, 2.5595e-01,\n",
      "        2.9411e-01, 1.4297e-01, 1.7278e-01, 2.3788e-01, 1.5332e-01, 9.7519e-01,\n",
      "        9.9534e-01, 9.0854e-01, 9.2535e-02, 6.3400e-02, 3.2903e-01, 9.9747e-01,\n",
      "        4.4031e-03, 8.0191e-01, 8.3708e-01, 1.1540e-02, 8.9154e-01, 4.6801e-03,\n",
      "        4.7802e-01, 3.0267e-02, 7.1934e-01, 1.6615e-01, 8.9100e-01, 9.8250e-01,\n",
      "        7.1011e-01, 5.2541e-01, 6.9135e-03, 7.8486e-02, 9.8779e-01, 1.6022e-01,\n",
      "        4.9754e-03, 5.8879e-01, 9.9913e-01, 5.0556e-01, 7.6703e-04, 7.7629e-01,\n",
      "        6.4118e-01, 6.5497e-03, 3.2375e-01, 3.4706e-01, 9.9183e-01, 2.0185e-01,\n",
      "        9.9893e-01, 4.5694e-02, 3.1497e-01, 2.5444e-02, 9.0729e-03, 9.9790e-01,\n",
      "        5.0341e-01, 6.8927e-02, 3.0775e-03, 6.6384e-02, 2.9157e-01, 2.4142e-01,\n",
      "        2.4202e-02, 2.1949e-01, 4.8240e-02, 9.9743e-01, 8.2013e-01, 1.3528e-02,\n",
      "        2.1030e-01, 4.1631e-03, 1.1997e-01, 2.0657e-01, 2.7033e-01, 4.9666e-01,\n",
      "        5.5477e-04, 9.9904e-01, 9.9927e-01, 5.3613e-03, 1.2691e-01, 9.9943e-01,\n",
      "        1.2320e-01, 6.2104e-01, 7.1460e-01, 1.7223e-01, 1.1605e-03, 5.2886e-01,\n",
      "        2.9428e-01, 9.6258e-01])\n",
      "Ansys\n",
      "\n",
      "Ansys, Inc. is a global public company based in Canonsburg, Pennsylvania. It develops and markets multiphysics engineering simulation software for product design, testing and operation. Ansys was founded in 1970 by John Swanson. Swanson sold his interest in the company to venture capitalists in 1993. Ansys went public on NASDAQ in 1996. In the 2000s, Ansys made numerous acquisitions of other engineering design companies, acquiring additional technology for fluid dynamics, electronics design, and other physics analysis. Ansys became a component of the NASDAQ-100 index on December 23, 2019.\n",
      "\n",
      "Corporate history\n",
      "\n",
      "Origins\n",
      "The idea for Ansys was first conceived by John Swanson while working at the Westinghouse Astronuclear Laboratory in the 1960s. At the time, engineers performed finite element analysis (FEA) by hand. Westinghouse rejected Swanson's idea to automate FEA by developing general purpose engineering software, so Swanson left the company in 1969 to develop the software on his own. He founded Ansys under the name Swanson Analysis Systems Inc. (SASI) the next year, working out of his farmhouse in Pittsburgh.\n",
      "\n",
      "Swanson developed the initial Ansys software on punch-cards and used a mainframe computer that was rented by the hour. Westinghouse hired Swanson as a consultant, under the condition that\n"
     ]
    }
   ],
   "source": [
    "print(data[0][\"input_ids\"])\n",
    "print(len(data[0][\"prob_dis\"]), data[0][\"prob_dis\"])\n",
    "print(data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfcb3d",
   "metadata": {},
   "source": [
    "## PPL and Min-k Prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5450f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 21576.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack ppl AUC 0.5208, Accuracy 0.5290, TPR@5FPR of 0.0420\n",
      "\n",
      "Attack min_20% prob AUC 0.5257, Accuracy 0.5325, TPR@5FPR of 0.0440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "for d in tqdm(data):\n",
    "    e = {}\n",
    "    pred = {}\n",
    "    tar_ppl = np.exp(-np.mean(d[\"prob_dis\"].numpy()))\n",
    "    pred[\"ppl\"] = tar_ppl # larger for nonmember\n",
    "\n",
    "    k = int(len(d[\"input_ids\"]) * 0.2)\n",
    "    min_k_pro = np.sort(d[\"prob_dis\"].numpy())[:k]\n",
    "    pred[f\"min_20% prob\"] = -np.mean(min_k_pro).item()  # larger for nonmember\n",
    "    \n",
    "    e[\"pred\"] = pred\n",
    "    e[\"label\"] = d[\"label\"]\n",
    "    examples.append(e)\n",
    "    \n",
    "evaluate(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932ec0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3caa7cc7",
   "metadata": {},
   "source": [
    "## prediction conditioned on 1-length prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff85c38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack pre_len_1 AUC 0.5606, Accuracy 0.5545, TPR@5FPR of 0.0590\n",
      "\n",
      "Attack pre_len_1_dedup AUC 0.5618, Accuracy 0.5530, TPR@5FPR of 0.0460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(data_dir, f\"{data_file}-1.pkl\")\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data_1 = pkl.load(f)\n",
    "    \n",
    "for d, d_1 in zip(data, data_1):\n",
    "    pred = {}\n",
    "    diff = d_1[\"prob_dis\"][:, -1] / d[\"prob_dis\"][0:]\n",
    "    pred[\"pre_len_1\"] = torch.mean(diff).item()\n",
    "    probs_dedup = [d[\"prob_dis\"][0]]\n",
    "    probs_1_dedup = [d_1[\"prob_dis\"][0, -1]]\n",
    "    for i, input_id in enumerate(d[\"input_ids\"][1:]):\n",
    "        if input_id not in d[\"input_ids\"][:i]:\n",
    "            probs_dedup.append(d[\"prob_dis\"][i+1])\n",
    "            probs_1_dedup.append(d_1[\"prob_dis\"][i+1, -1])\n",
    "    diff_dedup = -(torch.tensor(probs_dedup)-torch.tensor(probs_1_dedup) / torch.tensor(probs_dedup))\n",
    "    pred[\"pre_len_1_dedup\"] = torch.mean(diff_dedup).item()\n",
    "    d[\"pred\"] = pred\n",
    "    \n",
    "evaluate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a732f",
   "metadata": {},
   "source": [
    "## prediction conditioned on 2-length prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3785cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack pre_len_2 AUC 0.5664, Accuracy 0.5580, TPR@5FPR of 0.0640\n",
      "\n",
      "Attack pre_len_2_dedup AUC 0.5227, Accuracy 0.5255, TPR@5FPR of 0.0490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(data_dir, f\"{data_file}-2.pkl\")\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data_2 = pkl.load(f)\n",
    "    \n",
    "for d, d_2 in zip(data, data_2):\n",
    "    pred = {}\n",
    "    diff = d_2[\"prob_dis\"][:, -1] / d[\"prob_dis\"][1:]\n",
    "    pred[\"pre_len_2\"] = torch.mean(diff).item()\n",
    "    probs_dedup = [d[\"prob_dis\"][1]]\n",
    "    probs_2_dedup = [d_2[\"prob_dis\"][0, -1]]\n",
    "    for i, input_id in enumerate(d[\"input_ids\"][2:]):\n",
    "        if input_id not in d[\"input_ids\"][:i-1]:\n",
    "            probs_dedup.append(d[\"prob_dis\"][i+1])\n",
    "            probs_2_dedup.append(d_2[\"prob_dis\"][i+1, -1])\n",
    "    diff_dedup = torch.tensor(probs_2_dedup) / torch.tensor(probs_dedup)\n",
    "    pred[\"pre_len_2_dedup\"] = torch.mean(diff_dedup).item()\n",
    "    d[\"pred\"] = pred\n",
    "    \n",
    "evaluate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bde3a8",
   "metadata": {},
   "source": [
    "## prediction conditioned on 3-length prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b971a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack pre_len_3 AUC 0.5685, Accuracy 0.5565, TPR@5FPR of 0.0750\n",
      "\n",
      "Attack pre_len_3_dedup AUC 0.5225, Accuracy 0.5260, TPR@5FPR of 0.0610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(data_dir, f\"{data_file}-3.pkl\")\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data_3 = pkl.load(f)\n",
    "    \n",
    "for d, d_3 in zip(data, data_3):\n",
    "    pred = {}\n",
    "    diff = d_3[\"prob_dis\"][:, -1] / d[\"prob_dis\"][2:]\n",
    "    pred[\"pre_len_3\"] = torch.mean(diff).item()\n",
    "    probs_dedup = [d[\"prob_dis\"][2]]\n",
    "    probs_3_dedup = [d_3[\"prob_dis\"][0, -1]]\n",
    "    for i, input_id in enumerate(d[\"input_ids\"][3:]):\n",
    "        if input_id not in d[\"input_ids\"][:i-2]:\n",
    "            probs_dedup.append(d[\"prob_dis\"][i+1])\n",
    "            probs_3_dedup.append(d_3[\"prob_dis\"][i+1, -1])\n",
    "    diff_dedup = torch.tensor(probs_3_dedup) / torch.tensor(probs_dedup)\n",
    "    pred[\"pre_len_3_dedup\"] = torch.mean(diff_dedup).item()\n",
    "    d[\"pred\"] = pred\n",
    "    \n",
    "evaluate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b3631",
   "metadata": {},
   "source": [
    "## prediction conditioned on 4-length prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2445fbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack pre_len_4 AUC 0.5708, Accuracy 0.5585, TPR@5FPR of 0.0920\n",
      "\n",
      "Attack pre_len_4_dedup AUC 0.5369, Accuracy 0.5305, TPR@5FPR of 0.0720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(data_dir, f\"{data_file}-4.pkl\")\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data_4 = pkl.load(f)\n",
    "    \n",
    "for d, d_4 in zip(data, data_4):\n",
    "    pred = {}\n",
    "    diff = d_4[\"prob_dis\"][:, -1] / d[\"prob_dis\"][3:]\n",
    "    pred[\"pre_len_4\"] = torch.mean(diff).item()\n",
    "    probs_dedup = [d[\"prob_dis\"][3]]\n",
    "    probs_4_dedup = [d_4[\"prob_dis\"][0, -1]]\n",
    "    for i, input_id in enumerate(d[\"input_ids\"][4:]):\n",
    "        if input_id not in d[\"input_ids\"][:i-3]:\n",
    "            probs_dedup.append(d[\"prob_dis\"][i+1])\n",
    "            probs_4_dedup.append(d_4[\"prob_dis\"][i+1, -1])\n",
    "    diff_dedup = torch.tensor(probs_4_dedup) / torch.tensor(probs_dedup)\n",
    "    pred[\"pre_len_4_dedup\"] = torch.mean(diff_dedup).item()\n",
    "    d[\"pred\"] = pred\n",
    "    \n",
    "evaluate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc2fff",
   "metadata": {},
   "source": [
    "## prediction conditioned on 5-length prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13e4e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack pre_len_5 AUC 0.5742, Accuracy 0.5630, TPR@5FPR of 0.1030\n",
      "\n",
      "Attack pre_len_5_dedup AUC 0.5345, Accuracy 0.5295, TPR@5FPR of 0.0650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(data_dir, f\"{data_file}-5.pkl\")\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data_5 = pkl.load(f)\n",
    "    \n",
    "for d, d_5 in zip(data, data_5):\n",
    "    pred = {}\n",
    "    diff = d_5[\"prob_dis\"][:, -1] / d[\"prob_dis\"][4:]\n",
    "    pred[\"pre_len_5\"] = torch.mean(diff).item()\n",
    "    probs_dedup = [d[\"prob_dis\"][4]]\n",
    "    probs_5_dedup = [d_5[\"prob_dis\"][0, -1]]\n",
    "    for i, input_id in enumerate(d[\"input_ids\"][5:]):\n",
    "        if input_id not in d[\"input_ids\"][:i-4]:\n",
    "            probs_dedup.append(d[\"prob_dis\"][i+1])\n",
    "            probs_5_dedup.append(d_5[\"prob_dis\"][i+1, -1])\n",
    "    diff_dedup = torch.tensor(probs_5_dedup) / torch.tensor(probs_dedup)\n",
    "    pred[\"pre_len_5_dedup\"] = torch.mean(diff_dedup).item()\n",
    "    d[\"pred\"] = pred\n",
    "    \n",
    "evaluate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a94ee",
   "metadata": {},
   "source": [
    "## prediction conditioned on 6-length prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1171d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack pre_len_6 AUC 0.5828, Accuracy 0.5645, TPR@5FPR of 0.0780\n",
      "\n",
      "Attack pre_len_6_dedup AUC 0.5255, Accuracy 0.5315, TPR@5FPR of 0.0420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(data_dir, f\"{data_file}-6.pkl\")\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data_6 = pkl.load(f)\n",
    "    \n",
    "for d, d_6 in zip(data, data_6):\n",
    "    pred = {}\n",
    "    diff = d_6[\"prob_dis\"][:, -1] / d[\"prob_dis\"][5:]\n",
    "    pred[\"pre_len_6\"] = torch.mean(diff).item()\n",
    "    probs_dedup = [d[\"prob_dis\"][5]]\n",
    "    probs_6_dedup = [d_6[\"prob_dis\"][0, -1]]\n",
    "    for i, input_id in enumerate(d[\"input_ids\"][6:]):\n",
    "        if input_id not in d[\"input_ids\"][:i-5]:\n",
    "            probs_dedup.append(d[\"prob_dis\"][i+1])\n",
    "            probs_6_dedup.append(d_6[\"prob_dis\"][i+1, -1])\n",
    "    diff_dedup = torch.tensor(probs_6_dedup) / torch.tensor(probs_dedup)\n",
    "    pred[\"pre_len_6_dedup\"] = torch.mean(diff_dedup).item()\n",
    "    d[\"pred\"] = pred\n",
    "    \n",
    "evaluate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bafd51b",
   "metadata": {},
   "source": [
    "## prediction conditioned on 7-length prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9022be55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack pre_len_7 AUC 0.5933, Accuracy 0.5795, TPR@5FPR of 0.0740\n",
      "\n",
      "Attack pre_len_7_dedup AUC 0.5201, Accuracy 0.5295, TPR@5FPR of 0.0550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(data_dir, f\"{data_file}-7.pkl\")\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data_7 = pkl.load(f)\n",
    "    \n",
    "for d, d_7 in zip(data, data_7):\n",
    "    pred = {}\n",
    "    diff = d_7[\"prob_dis\"][:, -1] / d[\"prob_dis\"][6:]\n",
    "    pred[\"pre_len_7\"] = torch.mean(diff).item()\n",
    "    probs_dedup = [d[\"prob_dis\"][6]]\n",
    "    probs_7_dedup = [d_7[\"prob_dis\"][0, -1]]\n",
    "    for i, input_id in enumerate(d[\"input_ids\"][7:]):\n",
    "        if input_id not in d[\"input_ids\"][:i-6]:\n",
    "            probs_dedup.append(d[\"prob_dis\"][i+1])\n",
    "            probs_7_dedup.append(d_7[\"prob_dis\"][i+1, -1])\n",
    "    diff_dedup = torch.tensor(probs_7_dedup) / torch.tensor(probs_dedup)\n",
    "    pred[\"pre_len_7_dedup\"] = torch.mean(diff_dedup).item()\n",
    "    d[\"pred\"] = pred\n",
    "    \n",
    "evaluate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24636039",
   "metadata": {},
   "source": [
    "## average prediction conditioned on [1-7]-length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af06c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack pre_len_[1-7] AUC 0.5827, Accuracy 0.5685, TPR@5FPR of 0.0950\n",
      "\n",
      "Attack pre_len_[1-7]_dedup AUC 0.5155, Accuracy 0.5265, TPR@5FPR of 0.0540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d, d_1, d_2, d_3, d_4, d_5, d_6, d_7 in zip(data, data_1, data_2, data_3, data_4, data_5, data_6, data_7):\n",
    "    pred = {}\n",
    "    d_avg = d_1[\"prob_dis\"][6:, -1] + d_2[\"prob_dis\"][5:, -1] + d_3[\"prob_dis\"][4:, -1] + d_4[\"prob_dis\"][3:, -1] + d_5[\"prob_dis\"][2:, -1] + d_6[\"prob_dis\"][1:, -1] + d_7[\"prob_dis\"][:, -1]\n",
    "    d_avg = d_avg / 7\n",
    "    diff = d_avg / d[\"prob_dis\"][6:]\n",
    "    pred[\"pre_len_[1-7]\"] = torch.mean(diff).item()\n",
    "    probs_dedup = [d[\"prob_dis\"][6]]\n",
    "    probs_7_dedup = [d_avg[0]]\n",
    "    for i, input_id in enumerate(d[\"input_ids\"][7:]):\n",
    "        if input_id not in d[\"input_ids\"][:i-6]:\n",
    "            probs_dedup.append(d[\"prob_dis\"][i+1])\n",
    "            probs_7_dedup.append(d_avg[i+1])\n",
    "    diff_dedup = torch.tensor(probs_7_dedup) / torch.tensor(probs_dedup)\n",
    "    pred[\"pre_len_[1-7]_dedup\"] = torch.mean(diff_dedup).item()\n",
    "    d[\"pred\"] = pred\n",
    "    \n",
    "evaluate(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd",
   "language": "python",
   "name": "dd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
